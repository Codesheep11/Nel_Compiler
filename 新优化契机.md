# transpose
矩阵转置优化,计算时将矩阵访问模式修改为符合数据局部性的
# h2
向量化和并行化，还有块状处理技术

块状处理（Blocking 或 Tiling）技术是一种优化方法，旨在提高程序的缓存利用率，从而提升程序性能。它主要应用于处理多维数组或矩阵的算法中，如矩阵乘法、卷积操作等。通过将大数组或矩阵分割成较小的块进行处理，可以有效减少缓存未命中（cache miss），提高数据局部性。

### 块状处理技术的基本思想

在许多算法中，特别是涉及多维数组的算法中，数据的访问模式可能会导致频繁的缓存未命中，因为数组元素可能相距较远，无法在缓存中很好地利用。块状处理技术通过将数组分割成较小的、可以完全放入缓存的块来解决这个问题。每次操作一个小块，这样在处理块中的数据时，缓存命中率会大大提高。

### 块状处理技术的实现步骤

1. **选择合适的块大小**：
    - 块的大小应该根据目标缓存层的大小来选择。通常选择可以放入L1或L2缓存的块大小。

2. **分割数据**：
    - 将数据分割成多个较小的块。对于二维数组或矩阵，可以将其划分成小的子矩阵。

3. **嵌套循环处理块**：
    - 外层循环遍历所有块，内层循环在每个块内进行计算。

### 块状处理技术示例

以下是一个矩阵乘法的简单示例，展示了如何应用块状处理技术：

```c
#include <stdio.h>

#define N 1024
#define BLOCK_SIZE 32

void matmul(float A[N][N], float B[N][N], float C[N][N]) {
    for (int i = 0; i < N; i += BLOCK_SIZE) {
        for (int j = 0; j < N; j += BLOCK_SIZE) {
            for (int k = 0; k < N; k += BLOCK_SIZE) {
                // 对每个块进行矩阵乘法
                for (int ii = i; ii < i + BLOCK_SIZE; ++ii) {
                    for (int jj = j; jj < j + BLOCK_SIZE; ++jj) {
                        for (int kk = k; kk < k + BLOCK_SIZE; ++kk) {
                            C[ii][jj] += A[ii][kk] * B[kk][jj];
                        }
                    }
                }
            }
        }
    }
}

int main() {
    float A[N][N], B[N][N], C[N][N] = {0};

    // 初始化矩阵 A 和 B
    for (int i = 0; i < N; ++i) {
        for (int j = 0; j < N; ++j) {
            A[i][j] = i * 0.01;
            B[i][j] = j * 0.01;
        }
    }

    // 矩阵乘法
    matmul(A, B, C);

    // 打印结果
    printf("C[0][0] = %f\n", C[0][0]);

    return 0;
}
```

### 块状处理技术的优点

- **提高缓存利用率**：通过将大数组分割成较小的块，可以更有效地利用缓存，减少缓存未命中。
- **提升数据局部性**：在处理块中的数据时，可以更好地利用数据的空间局部性和时间局部性。
- **改善性能**：在多核处理器上，可以更好地并行处理不同的块，进一步提升程序性能。

### 块状处理技术的应用场景

- **矩阵乘法**：如上例所示，块状处理技术可以显著提高矩阵乘法的性能。
- **卷积操作**：在图像处理和深度学习中，卷积操作也可以通过块状处理技术来优化。
- **其他涉及多维数组的算法**：如有限元分析、图像变换等。

块状处理技术是优化高性能计算程序的一种重要手段，特别适用于处理大规模数据集的算法。
# sl
不清楚

# shuffle
名字叫散列
# recurcall
看看尾递归能用吗
# matmul
别名分析+矩阵型化简
# largeloop array
纯并行点
# if-combine
左巴做吧
# h8 
并行点
# h7
识别求sqrt并且转化为硬件指令
# h6
深度学习的节点，advance
# h5
lu 分解
# h4
min max
# h3
又是一个并行的核函数
# h1
尾递归
# gameoflife
康威生命游戏
左巴当时是怎么做的来着
# fft
并行
# spmv
稀疏矩阵向量乘法
向量指令，byd，cuda有这样的实现，可以考虑慢慢做
# mm
矩阵乘法还是。。
可否继续池化？
